{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d282b2d",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9d16729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as sqla\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pymysql\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Load pre-trained word embeddings (e.g., spaCy's medium English model)\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from shapely.ops import nearest_points\n",
    "import geopandas as gpd\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf165be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venue_static = pd.read_csv('../data_models/Recommendation_model/venue_static.csv')\n",
    "df_venue_timings = pd.read_csv('../data_models/Recommendation_model/venue_timings.csv')\n",
    "df_venue_merged = pd.read_csv('../data_models/Recommendation_model/venue_merged.csv')\n",
    "\n",
    "# df_venue_static = pd.read_csv('venue_static.csv')\n",
    "# df_venue_timings = pd.read_csv('venue_timings.csv')\n",
    "# df_venue_merged = pd.read_csv('venue_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5810f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venue_static = df_venue_static[df_venue_static['venue_type'] != 'LIBRARY']\n",
    "# df_venue_static.to_csv('venue_static.csv', index=False)\n",
    "df_venue_static.to_csv('../data_models/Recommendation_model/venue_static.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ca397e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manhattan_zone = pd.read_csv('../data_models/Recommendation_model/manhattan_zones.csv')\n",
    "# df_manhattan_zone = pd.read_csv('manhattan_zones.csv')\n",
    "#df_manhattan_zone.head(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e84e1ef",
   "metadata": {},
   "source": [
    "# Manipulate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f471e79",
   "metadata": {},
   "source": [
    "## Split into Hour and Day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2b31d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venue_merged['merged_time'] = pd.to_datetime(df_venue_merged['merged_time'])\n",
    "\n",
    "# Add 'day_of_week' column (Monday as 0)\n",
    "df_venue_merged['day_of_week'] = df_venue_merged['merged_time'].dt.dayofweek\n",
    "\n",
    "# Add 'hour_integer' column\n",
    "df_venue_merged['hour_integer'] = df_venue_merged['merged_time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3ab6ae57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(df_venue_merged.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78812016",
   "metadata": {},
   "source": [
    "## Grouping Venue Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e18f1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_mapping = {\n",
    "    'PARK': 'Park',\n",
    "    'TOURIST_DESTINATION': 'Tourist Destination',\n",
    "    'MUSEUM': 'Cultural Heritage',\n",
    "    'HISTORICAL':'Cultural Heritage',\n",
    "    'SCENIC_POINT': 'Scenic Landmarks',\n",
    "    'BRIDGE': 'Scenic Landmarks',\n",
    "    'NATURE_RESERVE': 'Nature Attractions',\n",
    "    'ZOO': 'Nature Attractions',\n",
    "    'BOTANICAL_GARDEN': 'Nature Attractions',\n",
    "    'ARTS': 'Art',\n",
    "    'DESSERT':'Art',\n",
    "    'CHURCH': 'Religious',\n",
    "    'SYNAGOGUE':'Religious',\n",
    "    'VISITOR_CENTER': 'Tourist Destination',\n",
    "    'LIBRARY':'Library',\n",
    "    'SHOPPING_CENTER': 'Shopping Center',\n",
    "    'APPAREL':'Fashion Convenience',\n",
    "    'OTHER': 'Tourist Destination',\n",
    "    'SHOPPING': 'Fashion Convenience',\n",
    "    'CONVENIENCE_STORE':'Neighborhood Market',\n",
    "    'SUPERMARKET': 'Neighborhood Market',\n",
    "    'GROCERY':'Neighborhood Market',\n",
    "    'MARKET':'Neighborhood Market',\n",
    "    'GIFTS': 'Gifts & Souvenirs',\n",
    "    'SOUVENIR_SHOP':'Gifts & Souvenirs',\n",
    "    \n",
    "}\n",
    "\n",
    "df_venue_static['venue_mod_type'] = df_venue_static['venue_type'].replace(venue_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1d77b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_to_zone_dict = {}\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in df_venue_static.iterrows():\n",
    "    venue_type = row['venue_mod_type']\n",
    "    zone = row['zone_id']\n",
    "    \n",
    "    # If the venue_type is already in the dictionary, append the zone to its list\n",
    "    if venue_type in venue_to_zone_dict:\n",
    "        venue_to_zone_dict[venue_type].append(zone)\n",
    "    # If the venue_type is not in the dictionary, create a new entry with the zone as a list\n",
    "    else:\n",
    "        venue_to_zone_dict[venue_type] = [zone]\n",
    "\n",
    "#print(venue_to_zone_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "202966d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_venue_static.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd513591",
   "metadata": {},
   "source": [
    "# Clearing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "956cabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for duplicates\n",
    "#print('Number of duplicate (excluding first) rows in the table is: ', df_venue_static.duplicated().sum())\n",
    "\n",
    "# use \"keep=False\" to mark all duplicates as true, including the original rows that were duplicated\n",
    "#print('Number of duplicate rows (including first) in the table is:', df_venue_static[df_venue_static.duplicated(keep=False)].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "51881083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for duplicates\n",
    "#print('Number of duplicate (excluding first) rows in the table is: ', df_venue_timings.duplicated().sum())\n",
    "\n",
    "# use \"keep=False\" to mark all duplicates as true, including the original rows that were duplicated\n",
    "#print('Number of duplicate rows (including first) in the table is:', df_venue_timings[df_venue_timings.duplicated(subset=['venue_id', 'day', 'opening_time', 'closing_time'], keep='first')].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "82dee57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Number of duplicate (excluding first) rows in the table is: ', df_venue_timings.drop_duplicates(subset=['venue_id', 'day', 'opening_time', 'closing_time'], inplace=True))\n",
    "#df_venue_timings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a1268",
   "metadata": {},
   "source": [
    "# Grouping Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6651ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_zone_grouping = {\n",
    "    'Upper Manhattan': [128, 127, 243, 120, 244, 116, 42, 152, 41, 74, 75],\n",
    "    'Upper West Side': [166, 24, 151, 43, 238, 239, 143, 142],\n",
    "    'Upper East Side': [236,263, 262, 237, 141, 140 ],\n",
    "    'Chelsea/Greenwhich market':[246, 68, 186, 90, 100, 234, 158, 249, 113, 249],\n",
    "    'Lower Manhattan': [107, 224, 114, 211, 144, 148, 232, 231, 45, 13, 261, 209, 87, 88, 12 ],\n",
    "    'Midtown Manhattan': [50, 48, 230, 163, 161, 162, 229, 233, 164, 170, 137, 224, 107, 234]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bc59c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# venue_zone_grouping dictionary\n",
    "venue_zone_grouping = {\n",
    "    'Upper Manhattan': [128, 127, 243, 120, 244, 116, 42, 152, 41, 74, 75],\n",
    "    'Upper West Side': [166, 24, 151, 43, 238, 239, 143, 142],\n",
    "    'Upper East Side': [236, 263, 262, 237, 141, 140],\n",
    "    'Chelsea/Greenwhich market': [246, 68, 186, 90, 100, 234, 158, 249, 113, 249],\n",
    "    'Lower Manhattan': [107, 224, 114, 211, 144, 148, 232, 231, 45, 13, 261, 209, 87, 88, 12],\n",
    "    'Midtown Manhattan': [50, 48, 230, 163, 161, 162, 229, 233, 164, 170, 137, 224, 107, 234],\n",
    "}\n",
    "\n",
    "# Function to map zone numbers to zone groups\n",
    "def map_zone_group(zone_number):\n",
    "    for zone_group, zone_numbers in venue_zone_grouping.items():\n",
    "        if zone_number in zone_numbers:\n",
    "            return zone_group\n",
    "    return 'Other'  # If zone number not found in the dictionary, assign 'Other'\n",
    "\n",
    "# Create the 'zone_group' column based on the mapping\n",
    "df_venue_static['zone_group'] = df_venue_static['zone_id'].apply(map_zone_group)\n",
    "\n",
    "#print(df_venue_static)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1b852085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_venue_static.to_csv('zone_Grouping.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7304da8b",
   "metadata": {},
   "source": [
    "# Extracting Only Attratcion Types and Ignoring Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d3f2309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_type_values = df_venue_static['venue_mod_type'].unique()\n",
    "# unique_type_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae74f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_venue_types = ['Nature Attractions', 'Shopping Center', 'Tourist Destination', 'Cultural Heritage', 'Neighborhood Market', 'Fashion Convenience',  'Scenic Landmarks', 'Art', 'Religious', 'Park', 'Gifts & Souvenirs']\n",
    "\n",
    "# Filter the DataFrame to only include rows with the specific venue types\n",
    "df_venue_static_att = df_venue_static[df_venue_static['venue_mod_type'].isin(specific_venue_types)]\n",
    "\n",
    "# Now 'filtered_df' contains only rows where the \"Attraction_Type\" is in the specified list\n",
    "# print(df_venue_static_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "17bf8b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_type_values_att = df_venue_static_att['venue_mod_type'].unique()\n",
    "# unique_type_values_att"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3a574",
   "metadata": {},
   "source": [
    "# Actual Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774716c2",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6ab6a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get user input with constraints\n",
    "def get_user_input(prompt, max_entries, existing_entries=[]):\n",
    "    # Replace underscores with spaces for existing entries\n",
    "    existing_entries = [entry.replace('_', ' ') for entry in existing_entries]\n",
    "    \n",
    "    user_input_list = []\n",
    "    for i in range(max_entries):\n",
    "        entry = input(f\"{prompt} {i+1}/{max_entries} (Leave empty to stop entering): \").strip()\n",
    "        \n",
    "        # Replace underscores with spaces for user's entry\n",
    "        entry = entry.replace('_', ' ')\n",
    "        \n",
    "        while entry in existing_entries or entry in user_input_list:\n",
    "            entry = input(f\"Invalid! {prompt} {i+1}/{max_entries} already entered. Please re-enter or leave empty to stop: \").strip()\n",
    "            \n",
    "            # Replace underscores with spaces again for the new entry\n",
    "            entry = entry.replace('_', ' ')\n",
    "            \n",
    "        if entry == \"\":\n",
    "            break\n",
    "        user_input_list.append(entry)\n",
    "    return user_input_list\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "params = sys.argv[1:]\n",
    "substrings = params[0].split(',')\n",
    "user_zone_input = substrings\n",
    "user_zone_input = [attraction.replace('_', ' ') for attraction in user_zone_input]\n",
    "\n",
    "substrings = params[1].split(',')\n",
    "user_input_attractions = substrings\n",
    "user_input_attractions = [attraction.replace('_', ' ') for attraction in user_input_attractions]\n",
    "\n",
    "\n",
    "# user_zone_input = [\"Chelsea/Greenwhich market\",\"Upper Manhattan\"]\n",
    "\n",
    "# user_input_attractions = [\n",
    "#         \"Tourist Destination\",\n",
    "#         \"Fashion Convenience\",\n",
    "#         \"Neighborhood Market\",\n",
    "#         \"Shopping Center\"\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c91c9663",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(user_input_attractions) < 4:\n",
    "    x = 4 - len(user_input_attractions)\n",
    "    \n",
    "    updated_list = [num for num in unique_type_values_att if num not in user_input_attractions]\n",
    "    \n",
    "    # Always include either 'Park', 'Scenic Landmark', or 'Tourist Destination' if not in user's input\n",
    "    core_attractions = ['Park', 'Scenic Landmarks', 'Tourist Destination']\n",
    "    \n",
    "    # Find out which core attractions are not in the user's input\n",
    "    missing_core_attractions = [attraction for attraction in core_attractions if attraction not in user_input_attractions]\n",
    "    \n",
    "    # Compute similarities only for missing core attractions\n",
    "    core_similarities = []\n",
    "    user_input_tag_embedding = nlp(user_input_attractions[0]).vector\n",
    "\n",
    "    for tag in missing_core_attractions:\n",
    "        tag_embedding = nlp(tag).vector\n",
    "        similarity = user_input_tag_embedding.dot(tag_embedding) / (np.linalg.norm(user_input_tag_embedding) * np.linalg.norm(tag_embedding))\n",
    "        core_similarities.append(similarity)\n",
    "\n",
    "    # Add the most similar core attraction to user's input\n",
    "    if core_similarities:\n",
    "        most_similar_core_index = np.argmax(core_similarities)\n",
    "        user_input_attractions.append(missing_core_attractions[most_similar_core_index])\n",
    "        x -= 1  # Decrement x as we've added a core attraction\n",
    "\n",
    "    # Now, for the remaining attractions (if any)\n",
    "    if x > 0:\n",
    "        other_similarities = []\n",
    "        \n",
    "        for tag in updated_list:\n",
    "            tag_embedding = nlp(tag).vector\n",
    "            similarity = user_input_tag_embedding.dot(tag_embedding) / (np.linalg.norm(user_input_tag_embedding) * np.linalg.norm(tag_embedding))\n",
    "            other_similarities.append(similarity)\n",
    "\n",
    "        sorted_indices = np.argsort(other_similarities)[::-1]  # Descending order\n",
    "        most_similar_tags = [updated_list[i] for i in sorted_indices]\n",
    "        slice_most_similar_tags = most_similar_tags[0:x]\n",
    "        user_input_attractions = user_input_attractions + slice_most_similar_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7bef30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_input_attractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7324de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "priority_table = pd.DataFrame({\n",
    "    'Attraction': ['Park', 'Tourist Destination', 'Cultural Heritage', 'Scenic Landmarks', 'Nature Attractions',\n",
    "                   'Religious', 'Art',  'Shopping Center', 'Fashion Convenience',\n",
    "                   'Neighborhood Market', 'Gifts & Souvenirs'],\n",
    "    'Opening_Time': ['9:00 AM', '9:00 AM', '11:00 AM', '9:00 AM', '10:00 AM', '11:00 AM', '10:00 AM', \n",
    "                     '10:00 AM', '10:00 AM', '10:00 AM', '10:00 AM'],\n",
    "    'Closing_Time': ['6:00 PM', '6:00 PM', '6:00 PM', '11:00 PM', '6:00 PM', '6:00 PM', '6:00 PM', \n",
    "                     '6:00 PM', '6:00 PM', '6:00 PM', '6:00 PM']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b04f7a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the following structure for df_venue_static_att: ['venue_id', 'venue_mod_type']\n",
    "\n",
    "# 1. Get the venue_id for each venue_mod_type from df_venue_static_att\n",
    "venue_ids_per_type = df_venue_static_att.groupby('venue_type')['hash_ven_id'].apply(list).to_dict()\n",
    "\n",
    "# 2. Use the venue_id to filter entries in df_venue_timings\n",
    "hourly_counts = {}\n",
    "for hour in range(24):  # 24 hours\n",
    "    for venue_type, venue_ids in venue_ids_per_type.items():\n",
    "        mask = (df_venue_timings['venue_id'].isin(venue_ids)) & \\\n",
    "               (df_venue_timings['opening_time'] <= hour) & \\\n",
    "               (df_venue_timings['closing_time'] >= hour) & \\\n",
    "               (df_venue_timings['day'] == 6)  # Assuming 6 represents Sunday\n",
    "        count = len(df_venue_timings[mask])\n",
    "        if venue_type not in hourly_counts:\n",
    "            hourly_counts[venue_type] = {}\n",
    "        hourly_counts[venue_type][hour] = count\n",
    "\n",
    "# 3. Determine most common opening and closing times\n",
    "common_times = {}\n",
    "for venue_type, counts in hourly_counts.items():\n",
    "    open_hour = min(counts.keys())\n",
    "    close_hour = max(counts.keys())\n",
    "    common_times[venue_type] = {\n",
    "        'Opening_Time': f'{open_hour}:00 AM' if open_hour < 12 else f'{open_hour-12 if open_hour > 12 else 12}:00 PM',\n",
    "        'Closing_Time': f'{close_hour}:00 AM' if close_hour < 12 else f'{close_hour-12 if close_hour > 12 else 12}:00 PM'\n",
    "    }\n",
    "\n",
    "# 4. Update the priority table\n",
    "for index, row in priority_table.iterrows():\n",
    "    attraction = row['Attraction']\n",
    "    if attraction in common_times:\n",
    "        priority_table.at[index, 'Opening_Time'] = common_times[attraction]['Opening_Time']\n",
    "        priority_table.at[index, 'Closing_Time'] = common_times[attraction]['Closing_Time']\n",
    "\n",
    "# print(priority_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7b7ee326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Sort attractions based on their opening times\n",
    "priority_table['Opening_Timestamp'] = pd.to_datetime(priority_table['Opening_Time'])\n",
    "sorted_attractions = priority_table.set_index('Attraction').loc[user_input_attractions].sort_values('Opening_Timestamp').index.tolist()\n",
    "\n",
    "# Initialize the itinerary dictionary\n",
    "itinerary = {}\n",
    "\n",
    "# Set the day's starting and ending time\n",
    "start_of_day = pd.Timestamp(f\"{current_date} 9:00 AM\")\n",
    "lunch_start = pd.Timestamp(f\"{current_date} 1:00 PM\")\n",
    "lunch_end = pd.Timestamp(f\"{current_date} 3:00 PM\")\n",
    "dinner_start = pd.Timestamp(f\"{current_date} 7:00 PM\")\n",
    "dinner_end = pd.Timestamp(f\"{current_date} 9:00 PM\")\n",
    "end_of_day = pd.Timestamp(f\"{current_date} 9:00 PM\")\n",
    "current_time = start_of_day\n",
    "\n",
    "for attraction in sorted_attractions:\n",
    "    row = priority_table[priority_table['Attraction'] == attraction].iloc[0]\n",
    "    opening_time = pd.Timestamp(f\"{current_date} {row['Opening_Time']}\")\n",
    "    closing_time = pd.Timestamp(f\"{current_date} {row['Closing_Time']}\")\n",
    "\n",
    "    # Skip if the attraction is already closed or will not open today\n",
    "    if current_time > closing_time or current_time < opening_time:\n",
    "        continue\n",
    "\n",
    "    # If it's lunchtime, jump to after lunch.\n",
    "    if lunch_start <= current_time < lunch_end:\n",
    "        current_time = lunch_end\n",
    "    \n",
    "    # If it's dinnertime, jump to after dinner.\n",
    "    if dinner_start <= current_time < dinner_end:\n",
    "        current_time = dinner_end\n",
    "\n",
    "    # Set the current time to the opening time if it's earlier\n",
    "    if current_time < opening_time:\n",
    "        current_time = opening_time\n",
    "\n",
    "    # Calculate the visit duration (min of 2 hours or available time)\n",
    "    visit_duration = min(2, (closing_time - current_time).seconds / 3600)\n",
    "\n",
    "    # Add to the itinerary if within the day's limit\n",
    "    if current_time + pd.Timedelta(hours=visit_duration) <= end_of_day:\n",
    "        itinerary[attraction] = f\"{current_time.strftime('%I:%M %p')} - {(current_time + pd.Timedelta(hours=visit_duration)).strftime('%I:%M %p')}\"\n",
    "        current_time += pd.Timedelta(hours=visit_duration)  # No buffer added here\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Print the suggested itinerary\n",
    "# print(\"Suggested Itinerary:\", itinerary)\n",
    "itinerary_timing = itinerary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "47262a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_group = []\n",
    "for group in user_zone_input:\n",
    "    for zone in venue_zone_grouping[group]:\n",
    "        zone_group.append(zone)\n",
    "# zone_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a367d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_type_dict = {}\n",
    "for venue_type in itinerary_timing:\n",
    "    matched_zones = df_venue_static_att[df_venue_static_att['venue_mod_type'] == venue_type]['zone_id'].unique()\n",
    "    zone_type_dict[venue_type] = list(matched_zones)\n",
    "\n",
    "# Print the resulting dictionary\n",
    "# print(zone_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9d6eccb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_venue_per_type_dict = {}\n",
    "for venue_type in itinerary_timing:\n",
    "    matched_zones = df_venue_static_att[df_venue_static_att['venue_mod_type'] == venue_type]['zone_id']\n",
    "    matching_zones = matched_zones[matched_zones.isin(zone_group)]\n",
    "    result_df = df_venue_static_att[df_venue_static_att['zone_id'].isin(matching_zones)]['original_ven_id']\n",
    "    user_venue_per_type_dict[venue_type] = list(result_df)\n",
    "\n",
    "# Print the resulting dictionary\n",
    "# print(user_venue_per_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "96dcb287",
   "metadata": {},
   "outputs": [],
   "source": [
    "types_with_zero_zones = []\n",
    "\n",
    "# Iterate through the venue_type_dict\n",
    "for venue_type, zones in user_venue_per_type_dict.items():\n",
    "    if len(zones) == 0:\n",
    "        types_with_zero_zones.append(venue_type)\n",
    "\n",
    "# print(\"Venue types with 0 zones:\", types_with_zero_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "95946cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance_between_zones(zone1_polygon, zone2_polygon):\n",
    "    # Find the nearest points between the two polygons\n",
    "    nearest_points_result = nearest_points(wkt.loads(zone1_polygon), wkt.loads(zone2_polygon))\n",
    "\n",
    "    # Calculate the distance between the nearest points\n",
    "    distance = nearest_points_result[0].distance(nearest_points_result[1])\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "51d0ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_type_with_zero_zone = {}\n",
    "\n",
    "for ven_type in types_with_zero_zones:\n",
    "    venue_to_zone_dict_copy = list(set(venue_to_zone_dict[ven_type]))\n",
    "    \n",
    "    if len(venue_to_zone_dict_copy) <= 0: # Modified condition\n",
    "        #get all venue id of each zone and push it to user_venue_per_type_dict of that type\n",
    "        # print('okay')\n",
    "        continue  # Continue to next iteration of the loop\n",
    "    \n",
    "    zone_between_dist = []\n",
    "    for user_zone in zone_group:\n",
    "        for venue_zone in venue_to_zone_dict_copy:\n",
    "            zone1_polygon = df_manhattan_zone[df_manhattan_zone['LocationID'] == user_zone]['the_geom'].iloc[0]\n",
    "            zone2_polygon = df_manhattan_zone[df_manhattan_zone['LocationID'] == venue_zone]['the_geom'].iloc[0]\n",
    "            distance = find_distance_between_zones(zone1_polygon, zone2_polygon)\n",
    "            zone_between_dist.append((user_zone, venue_zone, distance)) \n",
    "\n",
    "    sorted_zone_between_dist = sorted(zone_between_dist, key=lambda x: x[2])[:3]\n",
    "    new_zone = [df_venue_static_att[\n",
    "        (df_venue_static_att['zone_id'] == item[1]) &\n",
    "        (df_venue_static_att['venue_mod_type'] == ven_type)\n",
    "    ]['original_ven_id'].tolist() for item in sorted_zone_between_dist]\n",
    "    \n",
    "    filled_type_with_zero_zone[ven_type] = list(set(item for sublist in new_zone for item in sublist))\n",
    "\n",
    "# filled_type_with_zero_zone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7bdfa136",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in user_venue_per_type_dict.keys():\n",
    "    # Check if the value of the current key is an empty array\n",
    "    if len(user_venue_per_type_dict[key]) == 0:\n",
    "        # Check if the key exists in dictionary B\n",
    "        if key in filled_type_with_zero_zone:\n",
    "            # Replace the value in A with the value from B\n",
    "            user_venue_per_type_dict[key] = filled_type_with_zero_zone[key]\n",
    "# print(user_venue_per_type_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "39e48c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... [Other necessary imports, data, and current_date definition]\n",
    "\n",
    "# ... [Your code for generating the itinerary]\n",
    "\n",
    "# Now, for the venues\n",
    "filtered_venues = {}\n",
    "\n",
    "today_day_num = datetime.now().weekday()  # 0: Monday, 6: Sunday\n",
    "\n",
    "# Using the itinerary timings:\n",
    "for attraction, timing in itinerary.items():\n",
    "    start_time, end_time = [t.strip() for t in timing.split('-')]\n",
    "    start_hour = int(pd.Timestamp(f\"{current_date} {start_time}\").strftime('%H'))\n",
    "    end_hour = int(pd.Timestamp(f\"{current_date} {end_time}\").strftime('%H'))\n",
    "\n",
    "    valid_venues = []\n",
    "    for venue_id in user_venue_per_type_dict.get(attraction, []):  # Only work with venues in user input\n",
    "        venue_info = df_venue_timings.loc[df_venue_timings['venue_id'] == venue_id]\n",
    "        \n",
    "        if not venue_info.empty:\n",
    "            # Check if the venue is closed for the day\n",
    "            if venue_info['opening_time'].iloc[0] == -1 or venue_info['closing_time'].iloc[0] == -1:\n",
    "                continue\n",
    "\n",
    "            filtered_venue_info = venue_info.loc[(venue_info['day'] == today_day_num) \n",
    "                                                 & (venue_info['opening_time'] <= start_hour)\n",
    "                                                 & (venue_info['closing_time'] >= end_hour)]\n",
    "            if not filtered_venue_info.empty:\n",
    "                valid_venues.append(venue_id)\n",
<<<<<<< HEAD
    "\n",
=======
>>>>>>> 13e9eac33c186a8ea56f489b5dfefd6fc53609ae
    "        \n",
    "    if valid_venues:\n",
    "        filtered_venues[attraction] = valid_venues\n",
    "\n",
    "# print(filtered_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "11fb87b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulated_venues = {}\n",
    "\n",
    "# Loop through each venue type and check for the specified condition\n",
    "for venue_type, venue_ids in user_venue_per_type_dict.items():\n",
    "    valid_venues = []\n",
    "    for venue_id in venue_ids:\n",
    "        venue_hash_id = df_venue_static.loc[df_venue_static['original_ven_id'] == venue_id]['hash_ven_id']\n",
    "        venue_rating = df_venue_static.loc[df_venue_static['original_ven_id'] == venue_id]['rating'].item()\n",
    "        venue_hash_id = int(venue_hash_id)\n",
    "        df_venue_merged['venue_id'] = df_venue_merged['venue_id'].astype(int)\n",
    "        specific_venue_df = df_venue_merged.loc[df_venue_merged['venue_id'] == venue_hash_id]\n",
    "        average_busyness = specific_venue_df['busyness'].mean() \n",
    "        \n",
    "        weight_rating = 0.6\n",
    "        weight_busyness = 0.4\n",
    "        composite_score = (weight_rating * venue_rating) + (weight_busyness * average_busyness)\n",
    "        \n",
    "        \n",
    "        valid_venues.append((venue_id, venue_rating, average_busyness, composite_score))\n",
    "    if valid_venues:\n",
    "        manipulated_venues[venue_type] = valid_venues\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b83e9ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'order': 0, 'type': 'Tourist Destination', 'values': [('ven_673150687856684b77546b526b6f775a644d68505162354a496843', 4.7, 36.36363636363637, 17.365454545454547), ('ven_7767787947374f4c683962526b6f775a315135717161334a496843', 4.6, 33.565400843881854, 16.186160337552742), ('ven_415a37545a367078557066526b6f775a5a6271774a626e4a496843', 4.6, 33.333333333333336, 16.093333333333334)], 'type_cat': 'attraction'}, {'order': 1, 'type': 'Fashion Convenience', 'values': [('ven_63456b77786e474b757563526b6f775a39326e6c5031304a496843', 4.3, 40.78787878787879, 18.895151515151515), ('ven_456c6a3469774243445068526b6f775a3172364d5378424a496843', 4.2, 39.92424242424242, 18.48969696969697), ('ven_51717653514d7730366249526b6f77624e41797a6a39754a496843', 4.2, 38.083333333333336, 17.753333333333334)], 'type_cat': 'attraction'}, {'order': 2, 'type': 'Neighborhood Market', 'values': [('ven_6367354456587959525968526b6f77326a4172446665454a496843', 4.2, 43.20454545454545, 19.80181818181818), ('ven_6f4a3437455573596f624c526b6f77324c414e756756504a496843', 4.1, 42.04545454545455, 19.27818181818182), ('ven_63456b77786e474b757563526b6f775a39326e6c5031304a496843', 4.3, 40.78787878787879, 18.895151515151515)], 'type_cat': 'attraction'}, {'order': 3, 'type': 'Shopping Center', 'values': [('ven_6367354456587959525968526b6f77326a4172446665454a496843', 4.2, 43.20454545454545, 19.80181818181818), ('ven_674c306f645755326f547a526b6f775a68353967465a6c4a496843', 4.2, 40.06060606060606, 18.544242424242427), ('ven_673150687856684b77546b526b6f775a644d68505162354a496843', 4.7, 36.36363636363637, 17.365454545454547)], 'type_cat': 'attraction'}]\n"
     ]
    }
   ],
   "source": [
    "# top_3_venues = {}\n",
    "\n",
    "# # Loop through each venue type and its venues\n",
    "# for venue_type, venue_data in manipulated_venues.items():\n",
    "#     # Sort the venues based on the composite score (fourth element in the tuple, index 3)\n",
    "#     if len(venue_data) > 3:\n",
    "#         sorted_venues = sorted(venue_data, key=lambda x: x[3], reverse=True)\n",
    "    \n",
    "#         # Keep only the top 3 venues for each venue type\n",
    "#         top_3_venues[venue_type] = sorted_venues[:3]\n",
    "#     else:\n",
    "#         top_3_venues[venue_type] = venue_data\n",
    "\n",
    "# # Display the top 3 venues for each venue type\n",
    "# # for venue_type, top_venues in top_3_venues.items():\n",
    "# #     print(f\"Venue Type: {venue_type}\")\n",
    "# #     for rank, (venue_id, rating, busyness, score) in enumerate(top_venues, start=1):\n",
    "# #         print(f\"Rank {rank}: Venue ID: {venue_id}, Rating: {rating}, Busyness: {busyness}, Score: {score}\")\n",
    "# #     print()\n",
    "\n",
    "# print(top_3_venues)\n",
    "\n",
    "top_3_venues = {}\n",
    "\n",
    "# Loop through each venue type and its venues\n",
    "for venue_type, venue_data in manipulated_venues.items():\n",
    "    # Sort the venues based on the composite score (fourth element in the tuple, index 3)\n",
    "    if len(venue_data) > 3:\n",
    "        sorted_venues = sorted(venue_data, key=lambda x: x[3], reverse=True)\n",
    "    \n",
    "        # Keep only the top 3 venues for each venue type\n",
    "        top_3_venues[venue_type] = sorted_venues[:3]\n",
    "    else:\n",
    "        top_3_venues[venue_type] = venue_data\n",
    "\n",
    "# Display the top 3 venues for each venue type\n",
    "# for venue_type, top_venues in top_3_venues.items():\n",
    "#     print(f\"Venue Type: {venue_type}\")\n",
    "#     for rank, (venue_id, rating, busyness, score) in enumerate(top_venues, start=1):\n",
    "#         print(f\"Rank {rank}: Venue ID: {venue_id}, Rating: {rating}, Busyness: {busyness}, Score: {score}\")\n",
    "#     print()\n",
    "\n",
    "venue_keys = list(top_3_venues.keys())\n",
    "venue_values = list(top_3_venues.values())\n",
    "\n",
    "final_venues = []\n",
    "for i in range(0, len(venue_keys)):\n",
    "    # Check if the index is within the bounds of venue_values\n",
    "    if i < len(venue_values):\n",
    "        final_venues.append({\n",
    "            'order': i,\n",
    "            'type': venue_keys[i],\n",
    "            'values': venue_values[i],\n",
    "            'type_cat': 'attraction'\n",
    "        })\n",
    "\n",
    "print(final_venues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
